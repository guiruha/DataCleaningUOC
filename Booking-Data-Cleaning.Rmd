---
title: 'Práctica 2: Booking Data Cleaning'
author: "Gerard Alcalde and Guillem Rochina"
date: "2022-12-24"
output:
  word_document: default
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(tinytex.verbose = TRUE)
suppressWarnings(library(dplyr))
suppressWarnings(library(ggplot2))
suppressWarnings(library(tidyr))
suppressWarnings(library(lubridate))
suppressWarnings(library(stringr))
suppressWarnings(library(knitr))
suppressWarnings(library(VIM))
suppressWarnings(library(corrplot))
suppressWarnings(library(MASS))
```

## 1. DESCRIPCIÓN DEL DATASET

### ¿Por qué es importante y qué pregunta/problema pretende responder?

#### 1.1. Descripción general

El conjunto de datos ha tratar es el obtenido como resultado de la práctica anterior de Web Scraping. El dataset presenta los datos e indicadores más relevantes de cada uno de los hoteles encontrados en función de determinados criterios de búsqueda (ciudad, fecha de check-in, fecha de check-out, número de adultos, niños y habitaciones). En este dataset en concreto presentamos datos para distintas fechas (diciembre, marzo y junio), ciudades (barcelona, madrid, valencia), número de adultos, niños y habitaciones a fin de tener una muestra más amplia e informativa que la que nos daría una búsqueda con tan sólo unos parámetros fijos.

A continuación, se realiza una breve descripción de cada una de las variables disponibles antes de realizar la limpieza:

* **Name (str)**: Nombre del hotel.
* **City (str)**: Nombre de la ciudad donde se realiza la búsqueda.
* **Check-in (str)**: Fecha de entrada al hotel.
* **Check-out (str)**: Fecha de salida del hotel.
* **Adults (int)**: Nº de adultos para los que se realiza la reserva.
* **Num_rooms (int)**: Nº de habitaciones reservadas.
* **Address (str)**: Dirección postal del hotel, nombre de calle, barrio de la ciudad, código postal, etc.
* **Hotel_coordinates (str)**: Latitud y longitud de la ubicación del hotel.
* **Hotel_score (int)**: Nota general que recibe el hotel por los usuarios.
* **Hotel_scores (dict)**: Puntuaciones de cada una de las dimensiones que puede valorar un usuario.
* **Hotel description (list)**: Descripción aportada por el propietario del hotel
* **Features (list)**: Lista de servicios añadidos del hotel.
* **Room_data (dict)**: Conjunto de diccionarios que recogen las características de cada una de las habitaciones disponibles en el hotel.
* **Page_count (int)**: Posición en la que ha aparecido el hotel en el buscador.
* **Current_page (int)**: Página en la que ha aparecido el hotel en el buscador.

#### 1.2. Importancia y problema a responder

Aparecer en los primeros resultados de una búsqueda de un usuario por internet se ha convertido en los últimos años en una de las preocupaciones principales de cualquier negocio que busca hacerse un hueco en el mundo digital. Este fenómeno explica la proliferación de herramientas como el SEO y el SEM, mediante las cuales se intenta innovar (más allá del pago de tarifas para aparecer en las primeras páginas de búsqueda) a fin de lograr un mejor “posicionamiento” en buscadores como Google o Bing. El negocio hotelero no es una excepción en este caso.

No obstante, el uso de dichas herramientas no resulta útil si nos enfrentamos a un buscador dentro de una página web, como el caso que nos ocupa con Booking.com. ¿Qué hacer entonces? ¿Cómo mejorar el posicionamiento dentro de la web?

En la web del metabuscador de alojamientos encontramos que define a dichas posiciones entre los resultados como “ranking”, descrito por ellos mismos como el orden en el que se muestran los alojamientos disponibles en los resultados de búsqueda. En su blog “Booking.com Partner Hub” indican que los resultados son ordenados según la relevancia en base a las preferencias particulares de cada “cliente”, incluyendo en este caso también las “dinámicas del mercado”, el “rendimiento del alojamiento”, etc. Variable que poca información revela al interesado en que sus hoteles/alojamientos aparezcan en posiciones más “atractivas” para este.

El objetivo de este dataset es obtener las características que hacen que un hotel esté mejor posicionado que otro. El posicionamiento de los hoteles suele ser algo estático y por ello con una sola lectura de la página web puede ser suficiente.

En concreto, en el mismo post analizado se destaca la relevancia de revisar regularmente las “condiciones flexibles”, los comentarios, los precios externos, las promociones, la puntuación de la página del alojamiento… a fin de lograr escalar puestos en la clasificación.

Dado el impacto que puede tener en el negocio de un hotel el aparecer en posiciones más inmediatas del buscador, el presente proyecto pretende ser la continuación de la práctica 1, ofreciendo un análisis inferencial que destaque que factores tienen un mayor peso en el posicionamiento de un alojamiento en Booking.com.

## 2. LIMPIEZA DE LOS DATOS

A fin de iniciar el proceso de limpieza de datos, en primer lugar se debe realizar la lectura del fichero csv que obtuvimos en la práctica anterior. Como resultado de la función de R-base "read.csv" obtenemos un objeto data.frame, que manipularemos en la presente sección.

```{r}
# Lectura y breve descripción de los datos

booking <- read.csv("hotels_data.csv", header = TRUE)
summary(booking)
```

Como observamos tanto con la función "summary" como con la función "class" nos muestran que a cada variable se le ha asignado o bien la clase de entero o la de string. En concreto, muchas de las variables interpretadas como string se tratan de diccionarios y listas, factor que deberemos tener en cuenta a la hora de trabajar con estas variables.

```{r}
# Tipo de dato asignado a cada variable

res <- sapply(booking, function(x) class(x))
kable(data.frame(var=names(res), clase=as.vector(res)))
```

#### 2.1. Transformación de las variables en el formato adecuado

Como se ha comentado, existen algunas variables que presentan todavía una estructura no válida para tratarlos estadísticamente o introducirlos en un modelo de data mining o machine learning. En esta sección nos encargamos de tratar dichas columnas a fin de obtener nuevas variables con un formato adecuado, eliminando a su vez cualquier informaión que no nos sea de utilidad.

En primer lugar, cabe destacar que no todas las columnas que tenemos disponibles en el dataset nos ofrecen información relevante para nuestro problema. Por tanto, a fin de reducir la dimensionalidad de este, nos encargamos de eliminar las columnas con información redundante.

```{r}
# Seleccionamos con la función "select" de dplyr todas las columnas excepto name y search_date, que nos van a ser de poca utilidad.

booking <- booking %>%
  dplyr::select(-c("name", "search_date"))
```

La columna hotel_coordinates incluye tanto los valores de latitud como los de longitud, separados por una coma. Dado que ambos dos valores nos indica información distinta, pues la latitud nos proporcionar información de la posición en dirección norte o sur del ecuador y la longitud información de la posición en dirección este u oeste, en este caso hemos optado por separarlos en dos columnas distintas.

```{r}
# Separamos los valores de la variable hotel coordinates en dos nuevas columnas, latitud y longitud
# La columna hotel_coordinates se elimina en el proceso

booking <- booking %>%
  separate(hotel_coordinates, c("latitude", "longitude"), sep = ",")

booking$latitude <- as.numeric(booking$latitude)
booking$longitude <- as.numeric(booking$longitude)
```

Por su parte, "hotel_scores" alberga diccionarios en cada uno de los registros. Cada diccionario consta del nombre de cada dimensión (caracterísitca a valorar) como clave y la valoración que recibe como valor. Dado que R lo ha interpretado como un string, nuestro enfoque en su limpieza se ha basado en separar la información con comas y, una vez obtenidas todas las columnas resultantes, extraer los datos numéricos de cada registro para quedarnos solo con los scores de cada dimensión.

```{r}
# Definimos un vector con los nombres de las columnas a crear

columns <-  c("staff_score", "facilities_score", "cleanliness_score", "comfort_score", "value_for_money_score", "location_score", "free_wifi_score")

# Separamos los strings (diccionarios) en función de las comas y creamos las columnas correspondientes. La primera columna creada es una NA porque todos los primeros registros en cada diccionario están vacíos (por un fallo en la extracción de datos). Estableciendo la columna como NA, indicamos a la función separate que ignore dichos datos y no cree columna alguna para ellos.

booking <- booking %>%
  separate(hotel_scores, c(NA, "staff_score", "facilities_score", "cleanliness_score", "comfort_score", "value_for_money_score", "location_score", "free_wifi_score"), sep = ",")

# Extraemos los valores numéricos de cada columna con la función del paquete readr, "parse_number"

booking[columns] <- apply(booking[columns], 2, readr::parse_number)
```

Dado que de las fechas tan sólo nos interesa el mes en el que se realiza la reserva (un alojamiento con unas características determinadas pdría estar mejor posicionado en un determinado mes que en otro) procedemos a extraer dicha información de las variables "check-in" y "check-out". No obstante, por el momento no eliminamos dichas columnas y las transformamos a formato date por si a caso podemos hacer uso de ellas más adelante.

```{r}
booking <- booking %>%
  # Separamos el nombre del mes del resto de elementos del registro para check_in y check_out
  separate(check.in, c(NA, "month_in", NA), sep = "-", remove = FALSE) %>%
  separate(check.out, c(NA, "month_out", NA), sep = "-", remove = FALSE) %>%
  # Modificamos la columna check_in para que tenga el formato de fecha normal
  separate(check.in, c("day", "month", "year"), sep = "-") %>%
  mutate(month = ifelse(month == "March", "03", ifelse(month == "June", "06", "12"))) %>%
  unite("check_in", c(day, month, year), sep = "-") %>%
  # Modificamos la columna check_out para que tenga el formato de fecha normal
  separate(check.out, c("day", "month", "year"), sep = "-") %>%
  mutate(month = ifelse(month == "March", "03", ifelse(month == "June", "06", "12"))) %>%
  unite("check_out", c(day, month, year), sep = "-")

# Transformamos las columnas check_in y check_out al format date
booking["check_in"] <- as.Date.character(booking$check_in, "%d-%m-%Y")
booking["check_out"] <- as.Date(booking$check_out, "%d-%m-%Y")
```

De la columna address tan sólo nos interesa el código postal (el barrio no se incluye en todos los registros a diferencia del CP, así que hemos optado por quedarnos con estos valores), por lo que extraemos dicha información para crear una nueva columna llamada "postal_code", eliminando la información redundante en el proceso.

```{r}
# Hemos tenido que cambiar esta función para que el extract no diera problemas
Sys.setlocale('LC_ALL', 'C')
# Extraemos los valores de codigo postal de la columna addres utilizando expressiones regulares
booking <- booking %>%
  extract(address, c("postal_code"), regex = "( [0-9]{5} )")

```

Los features, entendidos como servicios adicionales más allá de la propia habitación, fueron guardados como una lista. No obstante, de nuevo nos encontramos como R lo ha identificado como string. Es por ello por lo que realizamos un tratamiento similar al de la columna de scores. En este caso creamos tantas variables dummy (columnas dicotómicas con valores de 1, en caso de que el feature exista en dicho registro, o 0, en caso de que no existe) como servicios adicionales de hotel consideramos interesantes.

```{r}
# Definimos las features que consideramos que son interesantes. Utilizamos este formato para filtrar por expresión regular.
feature_list <- c("('Free Wifi')", "('Air conditioning')", "('24-hour front desk')", "('Safe')", "('Heating')", "('Elevator')", "('Private Bathroom')", "('Non-smoking rooms')", "('Aparments')", "('City view')","('Kitchen')", "('Pet Friendly')", "('Swimming pool')", "('Balcony')")

# Creamos un bucle en el que se recorre cada elemento de la lista de features
for (feature in feature_list){
  # Se eliminan los parentésis y comillas de la variable local feature para crear el nombre de la columna.
  col_name <- str_replace(str_replace(str_to_lower(str_extract(feature, "([A-Z][a-z]*( |-)?[A-Z]?[a-z]* ? ?[a-z]*)")), " ", "_"), "-", "_")
  booking <- booking %>%
  # Extraemos el nombre del feature de cada uno de los registros (strings). En caso de que no encuentre ningún valor devuelve un NA.
  extract(features, c(col_name), regex = feature, remove = FALSE) %>%
  # Transformamos la columna que acaba de ser creada para que indique con un 1 si el registro tenia dicho servicio y 0 si el valor era NA (no tenida dicho servicio)
  mutate_(.dots = setNames(list(paste0("as.integer(!is.na(",col_name,"))")), col_name))
}

# Eliminamos la columna de features para finalizar
booking <- booking %>%
  dplyr::select(-c("features"))
```

Por otro lado, nos encontramos con la columna que incluye la descripción del hotel, esta descripción es muy amplia y un análisis profundo de ella requeriría de técnicas de NLP que no son el objetivo de esta práctica. No obstante, consideramos que la longitud de la descripción del hotel si que puede tener una relación con la posición en el buscador, por lo que transformaremos esta variable a una nueva variable que contenga el número total de palabras que contiene la descripción.

A continuación, se procesa la columna hotel_description para obtener el número de palabras que contiene la descripción que se almacena en la nueva columna length_description y a continuación se elimina esta columna ya que no se empleará en el resto del estudio.

```{r}
# Evaluamos la longitud de la descripción del hotel
booking$length_description <- lengths(gregexpr("\\W+", booking$hotel_description)) + 1

# Eliminamos la columna hotel_description
booking <- booking %>%
    dplyr::select(-c("hotel_description"))
```

Finalmente en la columna Room_data, se incluye mucha información referente a los tipos de habitaciones disponibles, precios, características, etc. Esta se había extraído de esta forma con el objetivo de procesarla mediante un diccionario de Python, no obstante al haber optado por un procesado con R este se complicará un poco más. En esta columna tenemos distintos datos que pueden ser muy relevantes que extraeremos, estos son:

* **min_price**: Precio de la habitación más económica.
* **suite_available**: Una de las habitaciones es de tipo suite.
* **apartment_available**: Una de la habitaciones es de tipo apartamento.
* **free_cancelation_available**: Alguna de las habitaciones tiene cancelación gratuita.


```{r}

# Función que encuentra el precio mínimo de la habitación dado un string con la información de las habitaciones
find_min_price <- function(text) {
  if (text=="{}"){
    return(0)
  }
  a <- gregexpr("([0-9]*', 'room_capacity)", text)
  
  min_price <- NA
  for (value in a[[1]]){
    substring <- substr(text, value, value+20)
    price <- as.numeric(strsplit(substring, "'")[[1]][1])
    if (is.na(min_price)) {
      min_price <- price
    }
    
    if (price < min_price) {
      min_price <- price
    } 
  }
  return(min_price)
}

# Aplicamos la función a todos los valores
min_price_vector <- c()
for (i in seq(1, length(booking$room_data))) {
  min_price_vector <- append(min_price_vector, find_min_price(booking$room_data[i]))
}

# Guardamos los resultados en una nueva columna.
booking$min_price <- min_price_vector

# Buscamos si hay una habitación en suite
is_suite_vector <- c()
for (i in seq(1, length(booking$room_data))) {
  is_suite <- gregexpr("(suite)", booking$room_data[i])[[1]][1]
  
  if (is_suite==-1) {
    is_suite_vector <- append(is_suite_vector, 0)
  } else {
    is_suite_vector <- append(is_suite_vector, 1)
  }
}

# Guardamos los resultados en una nueva columna.
booking$is_suite <- is_suite_vector

# Buscamos si hay opción de apartamento
is_apartment_vector <- c()
for (i in seq(1, length(booking$room_data))) {
  is_apartment <- gregexpr("(Apartment)", booking$room_data[i])[[1]][1]
  
  if (is_apartment==-1) {
    is_apartment_vector <- append(is_apartment_vector, 0)
  } else {
    is_apartment_vector <- append(is_apartment_vector, 1)
  }
}

# Guardamos los resultados en una nueva columna.
booking$is_apartment <- is_apartment_vector

# Buscamos si tiene cancelación gratuita
free_cancelation_vector <- c()
for (i in seq(1, length(booking$room_data))) {
  free_cancelation <- gregexpr("(Free cancellation)", booking$room_data[i])[[1]][1]
  
  if (free_cancelation==-1) {
    free_cancelation_vector <- append(free_cancelation_vector, 0)
  } else {
    free_cancelation_vector <- append(free_cancelation_vector, 1)
  }
}

# Guardamos los resultados en una nueva columna.
booking$has_free_cancelation <- free_cancelation_vector

# Eliminamos la columna correspondiente a room_data
booking <- booking %>%
  dplyr::select(-c("room_data"))

```


#### 2.2. Ceros y elementos vacíos

Dando paso a el tratamiento de ceros y elementos vacios, lo primero que debemos hacer es identificar aquellas variables en las que encontramos valores faltantes. Como observamos, "postal_code" (19), "longitude" (16), "hotel_score" (8) y el resto de variables relacionadas con los scores (60) presentan valores faltantes.

```{r}
sapply(booking, function(y) sum(length(which(is.na(y)))))
  
```

Por lo que respecta a la variable "postal_code" encontramos que en todos aquellos registros donde se encuentan NAs, también hallamos datos faltantes en la mayoría del resto de columnas. Por tanto, dado que dichos registros no nos aportan información de valor, procedemos a eliminarlos del dataset.

```{r}

# Comprobamos algunos de los registros donde hay datos faltantes de postal_code
booking[is.na(booking$postal_code),] %>%
  dplyr::select(c("city", "month_in", "postal_code", "longitude", "hotel_score", "staff_score", "location_score")) %>%
  head(10)

# Filtramos los datos para eliminar aquellos registros que tienen NAs en postal_code
booking <- booking[!is.na(booking$postal_code),]
  
```

Si comprobamos de nuevo que columnas presentan todavía datos faltantes, observamos que en algunos casos (como "longitude") hemos logrado eliminar todos los datos faltantes, mientras que en el resto se han reducido en 16 unidades el número de registros con NAs, pues como se había comentado todos aquellos registros con ausencia de postal_code, también carecía del resto de datos.

```{r}
sapply(booking, function(y) sum(is.na(y)))
```

A continuación, analizamos los datos faltantes de hotel_score. En este caso, encontramos que la ausencia de datos se registra de dos formas distintas, o bien con la introducción de NAs o bien con el valor -1. Por tanto, dado que el tratamiento en ambos casos va a ser el mismo, transformamos todos los valores -1 en NAs para poder llevar a cabo el siguiente proceso de inputación.

```{r}

# Comprobamos algunos de los registros donde hay datos faltantes de hotel_score
booking[is.na(booking$hotel_score),] %>%
  dplyr::select(c("city", "month_in", "hotel_score", "staff_score", "location_score", "longitude", "facilities_score", "cleanliness_score", "comfort_score")) %>%
  head(5)

```

```{r}

# Comprobamos algunos de los registros donde hay datos faltantes de hotel_score
booking[booking$hotel_score == "-1",] %>%
  dplyr::select(c("city", "month_in", "hotel_score", "staff_score", "location_score", "longitude", "facilities_score", "cleanliness_score", "comfort_score")) %>%
  tail(5)

booking[booking$hotel_score == "-1",] %>%
  dplyr::select(c("city", "month_in", "hotel_score", "staff_score", "free_wifi_score", "free_wifi")) %>%
  tail(10)


# Tranformamos los valores -1 en NAs para poder llevar a cabo el proceso de inputación correctamente.
booking$hotel_score <- ifelse(booking$hotel_score == "-1", NA, booking$hotel_score)

```

Dado que en este caso tan sólo encontramos datos faltantes en las columnas de score no consideramos eliminar estos registros, sino llevar a cabo una imputación. Aunque se podría haber utilizado una metología más simple como el uso de la media o la mediana, hemos optado por hacer uso de un método más complejo, basado en la similitud entre registros, en concreto llevar a cabo una imputación mediante el algoritmo de K vecinos más próximos. En este caso, la función se encarga de devolver los mismos valores en caso de que ya existan en el dataset y el valor de los registros más "similares" en el caso de un registro con NAs. No obstante, en el caso de "free_wifi_score" tan sólo introduciremos el valor de 0 en aquellos datos con ausencia de valores, pues tras analizar más en detenimiento los registros, aquellos con datos faltantes de free_wifi_score tienen un valor igual a 0 en la columna free_wifi, lo que nos indica ausencia de este servicio en el hotel.

```{r}

# Imputamos los datos con K Neirest Neighbours
booking$hotel_score <- kNN(booking)$hotel_score
booking$staff_score <- kNN(booking)$staff_score 
booking$facilities_score <- kNN(booking)$facilities_score
booking$cleanliness_score <- kNN(booking)$cleanliness_score
booking$comfort_score <- kNN(booking)$comfort_score
booking$value_for_money_score <- kNN(booking)$value_for_money_score
booking$location_score <- kNN(booking)$location_score
# Imputamos valores de 0 a la columan free_wifi_score
booking$free_wifi_score <- ifelse(is.na(booking$free_wifi_score), 0, booking$free_wifi_score)

```

Una última comprobación nos revela que el dataset ya no cuenta con datos faltantes, con independencia del formato que pudieran presenta (strings vacías, valores de -1 en integers, o simplemente NAs).

```{r}
sapply(booking, function(y) sum(is.na(y)))
```

```{r}

sapply(booking, function(y) sum(y == ""))

```

#### 2.3. Valores extremos

Los outliers son aquellos datos extremos que dada su distancia con respecto al grueso de la distribución a priori resultan no ser congruentes si los comparamos con la población/muestra analizada. Existen varias vías para detectarlos, no obstante el método más rápdio y común se basa en el uso de boxplots, donde se detectan aquellos valores que se sitúan 1.5 veces más allá del rango intercuartílico con respecto a la mediana. Asimismo, en este trabajo también haremos uso de la función "boxplots.stats()" a fin de detectar, con un output más allá del visual, los outliers que encontramos usando boxplots. Dado que muchas de las variables que hemos generado en la fase de limpieza son dicotómicas, tan solo nos encargaremos de comprobar si existen valores extremos en las columnas de **num_rooms**, **latitude**, **longitude**, **hotel_score** y el resto de **scores del hotel**, **length_description** y **min_price**.

```{r}

ggplot(booking, aes(y = num_rooms, color = city))+
  geom_boxplot() +
  facet_grid(~city)

boxplot.stats(booking$num_rooms)$out

```

```{r}

ggplot(booking, aes(y = latitude))+
  geom_boxplot(color = "navy", fill = "white")

boxplot.stats(booking$latitude)$out

```

```{r}

ggplot(booking, aes(y = longitude))+
  geom_boxplot(color = "navy", fill = "white")

boxplot.stats(booking$longitude)$out

```

```{r}

ggplot(booking, aes(y = hotel_score, color = city))+
  geom_boxplot() +
  facet_grid(~city)

boxplot.stats(booking$hotel_score)$out

```

```{r}

booking %>%
  filter(hotel_score <= 7.0) %>%
  sample_n(3)

```

```{r}

booking %>%
  filter(hotel_score == 10.0) %>%
  sample_n(3)

```

```{r}

ggplot(booking, aes(y = facilities_score, color = city))+
  geom_boxplot() +
  facet_grid(~city)

boxplot.stats(booking$facilities_score)$out

```

```{r}

booking %>%
  filter(facilities_score <= 6.5) %>%
  sample_n(3)

```

```{r}

ggplot(booking, aes(y = staff_score, color = city))+
  geom_boxplot() +
  facet_grid(~city)

boxplot.stats(booking$staff_score)$out

```

```{r}

booking %>%
  filter(staff_score <= 6.7) %>%
  sample_n(3)

```

```{r}

ggplot(booking, aes(y = cleanliness_score, color = city))+
  geom_boxplot() +
  facet_grid(~city)

boxplot.stats(booking$cleanliness_score)$out

```

```{r}

booking %>%
  filter(cleanliness_score < 7.0) %>%
  sample_n(3)

```

```{r}

ggplot(booking, aes(y = comfort_score, color = city))+
  geom_boxplot() +
  facet_grid(~city)

boxplot.stats(booking$comfort_score)$out

```

```{r}

booking %>%
  filter(comfort_score < 7.0) %>%
  sample_n(3)

```

```{r}

ggplot(booking, aes(y = value_for_money_score, color = city))+
  geom_boxplot() +
  facet_grid(~city)

boxplot.stats(booking$value_for_money_score)$out

```

```{r}

booking %>%
  filter(value_for_money_score <= 7.0) %>%
  sample_n(3)

```

```{r}

ggplot(booking, aes(y = location_score, color = city))+
  geom_boxplot() +
  facet_grid(~city)

boxplot.stats(booking$location_score)$out

```

```{r}

booking %>%
  filter(location_score < 7.0) %>%
  sample_n(3)

```

```{r}

ggplot(booking, aes(y = free_wifi_score, color = city))+
  geom_boxplot() +
  facet_grid(~city)

boxplot.stats(booking$free_wifi_score)$out

```

```{r}

booking %>%
  filter(free_wifi_score < 5.0 & free_wifi_score > 0) %>%
  sample_n(3)

```

```{r}

ggplot(booking, aes(y = length_description, color = city))+
  geom_boxplot() +
  facet_grid(~city)

boxplot.stats(booking$length_description)$out

```


```{r}

ggplot(booking, aes(y = min_price, color = city))+
  geom_boxplot() +
  facet_grid(~city)

boxplot.stats(booking$min_price)$out

```



#### 2.4. Exportación de los datos postprocesados

```{r}

#write.csv(booking, "hotel_data_processed.csv")

```

## 3. INTEGRACIÓN Y SELECCIÓN

En primer lugar, hemos obtado por añadir datos de vuelos por varias razones:

* Un mayor número de vuelos en un mes podría aumentar las búsquedas de hoteles cerca del aeropuerto.
* Un mayor número de vuelos en un mes indica más turismo internacional (en lugar de sólo turismo nacional). Un tipo de turismo que podría estar buscando hoteles con características diferentes a los turistas nacionales.
* Un mayor número de vuelos en un mes indica más turismo general, lo que puede influir en las estrategias de promoción y ofertas de determinados hoteles, influyendo en última instancia en su posición en el buscador Booking.

```{r}
# Leemos los datos de vuelos
flights <- read.csv("avia_tf_apal_linear.csv.gz")
summary(flights)
```

Para añadir dicha información hacemos un tratamiento de los datos obtenidos en Eurostat a fin de obtener una media de vuelos por mes para los últimos 5 años. Una vez obtenidos, tan solo debemos hacer un merge con nuestro dataset original.

```{r}
proc_flights <- flights %>% 
        # Filtramos para quedarnos solo con los aeropuertos de interés
        # Código OACI/ICAO: Barcelona --> ES_LEBL; Valencia --> ES_LEVC; Madrid: ES_LEMD
        filter(rep_airp %in% c("ES_LEBL", "ES_LEVC", "ES_LEMD")) %>% 
        # Filtramos para quedarnos solo con los datos de carga de pasajeros
        filter(tra_meas == "PAS_CRD") %>%
        # Nos interesa solo los datos mensuales, así que filtramos por ellos
        filter(freq == "M") %>%
        separate(TIME_PERIOD, c("YEAR", "MONTH"), sep = "-") %>%
        # Nos quedamos solo con los últimos 5 años y los meses de Marzo, Junio y Diciembre
        filter(YEAR %in% c("2022", "2021", "2020", "2019", "2018") & MONTH %in% c("03", "06", "12")) %>%
        # No nos interesa los datos por aerolínea, solo los generales
        filter(airline == "TOTAL") %>%
        # Modificamos la columna de MONTH para tener los nombres del mes y cambiamos el código del aeropuerto por el nombre de la ciudad
        mutate(month_name = ifelse(MONTH == "03", "March", ifelse(MONTH == "06", "June", "December")),
               city_airp = ifelse(rep_airp == "ES_LEBL", "Barcelona", ifelse(rep_airp == "ES_LEVC", "Valencia", "Madrid"))) %>%
        # Agrupamos por ciudad y mes y calculamos la media de vuelos.
        group_by(rep_airp, month_name) %>%
        mutate(mean_fligths = mean(OBS_VALUE)) %>%
        ungroup() %>%
        dplyr::select(c(city_airp, month_name, mean_fligths))

# Nos quedamos con los registros únicos
final_flights <- unique(proc_flights)

# Hacemos un merge con bookings
booking <- booking %>%
  merge(final_flights, by.x = c("city", "month_in"), by.y = c("city_airp", "month_name"))
```


## 4. ANÁLISIS DE LOS DATOS

En este apartado se procede a analizar los datos que previamente hemos preprocesado. El objetivo de este trabajo era obtener que factores influenciaban en el posicionamiento de un hotel en el buscador de Booking, para ello se recogieron distintas variables mediante webscrapping, las cuales se han almacenado y preprocesado en el dataframe **booking**.

A continuación se evaluará la influencia de las distintas variables sobre la posición de un hotel en el buscador, para ello se emplea una matriz de correlación. Una vez obtenidas las variables con mayor correlación con la variable objetivo generaremos una selección de los grupos de datos a analizar, separando los datos según los valores de estas variables correlacionadas con la variable objetivo.

Una vez generados los distintos grupos procederemos a evaluar la normalidad y la homogeneidad de la varianza para así poder determinar en el siguiente punto que pruebas estadísticas se pueden aplicar.

Finalmente aplicaremos distintas pruebas estadísticas adicionales a la correlación hayada inicialmente. Estas pruebas estadísticas incluirán contrastes de hipótesis y regresiones lineales.

#### 4.1 Correlación con la variable objetivo

Comenzamos evaluando la correlación entre las distintas variables con nuestra variable objetivo, para ello creamos una matriz de correlación y evaluamos los resultados obtenidos.

```{r}
# Transformamos las variables a numérico
booking$postal_code <- as.numeric(booking$postal_code)
booking$latitude <- as.numeric(booking$latitude)
booking$longitude <- as.numeric(booking$longitude)
booking$free_wifi <- as.numeric(booking$free_wifi)
#booking$apartments <- as.numeric(booking$apartments)
#booking$pet_friendly <- as.numeric(booking$pet_friendly)

# Seleccionamos solo las variables numéricas
booking_numeric <- booking %>%
  dplyr::select(-c("city", "month_in", "check_in", "month_out", "check_out", "as.integer(!is.na(NA))"))

mattmp <- booking_numeric %>%
  dplyr::select(c("adults", "children", "num_rooms", "postal_code", "latitude", "longitude", "hotel_score", "length_description", 
           "is_suite", "is_apartment", "has_free_cancelation", "min_price", "current_page", "in_page_count", "page_count"))

sapply(mattmp, function(y) sum(is.na(y)))

# Creamos una matriz de correlación del dataset
cor_mat <- cor(mattmp, method = "spearman")
plot.new()
plot.window(xlim=c(-2,2), ylim=c(5,10))
corrplot(cor_mat, method="color", type = "lower", tl.col = "black", tl.srt = 45, diag = FALSE, tl.cex = 0.55, addCoef.col = 'black', number.cex = 0.5)
```
```{r}
mattmp <- booking_numeric %>%
  dplyr::select(c("hotel_score", "staff_score", "facilities_score", "cleanliness_score", "comfort_score", "value_for_money_score", "location_score",
           "free_wifi_score", "min_price", "current_page", "in_page_count", "page_count"))

sapply(mattmp, function(y) sum(is.na(y)))

# Creamos una matriz de correlación del dataset
cor_mat <- cor(mattmp, method = "spearman")
plot.new()
plot.window(xlim=c(-2,2), ylim=c(5,10))
corrplot(cor_mat, method="color", type = "lower", tl.col = "black", tl.srt = 45, diag = FALSE, tl.cex = 0.55, addCoef.col = 'black', number.cex = 0.5)
```

```{r}
mattmp <- booking_numeric %>%
  dplyr::select(c("balcony", "swimming_pool", "pet_friendly", "kitchen", "city_view", "aparments", "non_smoking_rooms", "hotel_score", 
           "private_bathroom", "elevator", "heating", "safe", "air_conditioning", "free_wifi", "min_price", "current_page", "in_page_count", "page_count"))

sapply(mattmp, function(y) sum(is.na(y)))

# Creamos una matriz de correlación del dataset
cor_mat <- cor(mattmp, method = "spearman")
plot.new()
plot.window(xlim=c(-2,2), ylim=c(5,10))
corrplot(cor_mat, method="color", type = "lower", tl.col = "black", tl.srt = 45, diag = FALSE, tl.cex = 0.55, addCoef.col = 'black', number.cex = 0.5)
```

Observamos que variables como las distintas puntuaciones estan correlacionadas entre ellas, por lo que un hotel que haya obtenido una puntuación elevada en un aspecto generalmente también lo obtendrá en el resto. También encontramos que los hoteles con distintas atributos como aire acondicionado o baño privado suelen tener el resto de atributos.

```{r}

# Filtramos para obtener cuales son las variables más correlacionadas con nuestra variable objetivo, page_count
cor_mat <- cor(booking_numeric, method = "spearman")
cor_mat_df <- as.data.frame(cor_mat)
cor_mat_df %>%
  arrange(current_page) %>%
  dplyr::select(current_page)
```

No obstante cuando evaluamos la posición en la página web observamos que no hay una correlación elevada con ninguna variable, encontrando correlaciones por debajo de 0.12 en todos los casos lo cual es sorprendente. No obstante, se obta por evaluar la influencia de determinadas variables que han estado más correlacionadas con la variable objetivo y que son de tipo binario como es el caso de:

* **is_apartment**
* **kitchen**
* **air_conditioning**
* **elevator**
* **private_bathroom**
* **has_free_cancelation**

# ¿PROBAMOS A HACER UNA REGRESIÓN LINEAL PARA PRECIO? ADEMÁS DE LA REGRESIÓN LOGISTICA PARA LA PÁGINA EN LA QUE SE ENCUENTRA EL HOTEL
```{r}

# Filtramos para obtener cuales son las variables más correlacionadas con nuestra variable objetivo, page_count
cor_mat <- cor(booking_numeric, method = "spearman")
cor_mat_df <- as.data.frame(cor_mat)
cor_mat_df %>%
  arrange(min_price) %>%
  dplyr::select(min_price)
```

#### 4.1 Selección de los grupos de datos que se quieren analizar

#***************************************************************************************#
# FREE WIFI, APARTMENTS Y PET_FRIENDLY SOLO TIENE UN VALOR 0 (ES POR ERROR DEL CÓDIGO?) #
#                        EN MIN_PRICE HAY MUCHOS CEROS                                  #
#***************************************************************************************#

#### 4.2 Comprobación de la normalidad y homogeneidad de la varianza

Para comprobar si los valores de las variables de nuestro dataset se distribuyen o se aproximan a un población distribuida normalmente haremos un análisis visual, con QQ-Plots y Histogramas, y un análisis mediante el test Shapiro-Wilk.

```{r}
norm_cols <- c("hotel_score", "length_description", "hotel_score", "staff_score", "facilities_score", "cleanliness_score", "comfort_score", "value_for_money_score", "location_score", "free_wifi_score", "min_price")

booking_norm <- booking_numeric %>%
  dplyr::select(norm_cols)

par(mfrow=c(2,2))
for(i in 1:ncol(booking_norm)){
  qqnorm(booking_norm[,i], main = paste("QQ-Plot de ",colnames(booking_norm)[i]), col = "navy")
  qqline(booking_norm[,i], col = "red")
  hist(booking_norm[,i], main = paste("Histograma de ", colnames(booking_norm)[i]), xlab=colnames(booking_norm)[i], freq = FALSE)
}
```

Los QQ-plots y los histogramas nos muestran una distribuciones con una evidente asimetría negativa en la mayoría de los casos (excepto variables como length_description que muestran una asimetría más bien positiva, aunque podría ser influencia de un dato extremo que no ha sido considerado outlier), así como un evidente problema con las colas, pues en la mayoría de los casos los puntos se alejan de la línea roja, la cual corresponde a la hipotética distribución normal. Por tanto, a priori podríamos rechazar la hipótesis de normalidad de las variables. No obstante, tras ejecutar el test Shapiro-Wilk confirmamos de forma más fiable nuestras primeras conclusiones, pues todos los p-valores muestran valores muy inferiores a 0.05, rechazando en todos los casos la hipótesis nula sobre la normamlidad de los datos.

```{r}

lapply(booking_norm, shapiro.test)

```

A fin de aproximar más los datos a una distribución normal, se propone hacer una transformación de box-cox y comprobar si los datos efectivamente se aproximan más a una normal. Tras llevar a cabo este proceso, si bien los histogramas muestran en algunos casos una distribución "visualmente más normales" y los QQ-plots parecen mostrar que la transformación ha aliviado ligeramente el problema con las colas, los resultados de la transformación no han sido suficientes como para poder considerar que los datos se distribuyen como una normal. No obstante, no debemos preocuparnos demasiado por este problema, pues tenemos suficientes registros como para poder apoyarnos en el Teorema del Límite Central. Por ejemplo, el t-test asume que las medias de las diferentes muestras se distribuyen normalmente (siendo una muestra de más de 30 registros suficiente, como rule of thumb, para que el t-test sea válido aunque los datos no se distribuyan normalmente).

```{r}
norm_cols <- c("hotel_score", "length_description", "hotel_score", "staff_score", "facilities_score", "cleanliness_score", "comfort_score", "value_for_money_score", "location_score", "free_wifi_score", "min_price")

booking_norm$min_price <- ifelse(booking_norm$min_price == 0, 1, booking_norm$min_price)
booking_norm$free_wifi_score <- ifelse(booking_norm$free_wifi_score == 0, 1, booking_norm$free_wifi_score)

par(mfrow=c(2,3))
for(i in 1:ncol(booking_norm)){
  b <- boxcox(lm(booking_norm[,i] ~ 1))
  lambda <- b$x[which.max(b$y)]
  qqnorm((booking_norm[,i]^lambda - 1)/lambda, main = paste("QQ-Plot de ",colnames(booking_norm)[i]), col = "navy")
  qqline((booking_norm[,i]^lambda - 1)/lambda, col = "red")
  hist((booking_norm[,i]^lambda - 1)/lambda, main = paste("Histograma de ", colnames(booking_norm)[i]), xlab=colnames(booking_norm)[i], freq = FALSE)
}
```

Seguidamente, analizaremos la homocedasticidad mediante boxplots y varios test de homocedasticidad, o de homogeneidad de varianzas. En este caso, no podemos utilizar el test de Levene ni el de Barlett ya que son muy sensibles ante datos no normales y, como acabamos de presentar, los datos analizados no se aproximan en ningún caso a una normal.


PARA VER A QUÉ VARIABLES HAGO EL TEST TENGO QUE VER QUE TEST APLICAS EN LA SIGUIENTE PARTE GERARD.


```{r}

ggplot(booking, aes(x = city, y = min_price, color = city)) + 
  geom_boxplot()

```

```{r}

fligner.test(min_price ~ city, data = booking)

```

```{r}

ggplot(booking, aes(x = month_in, y = min_price, color = month_in)) + 
  geom_boxplot()

```

```{r}

fligner.test(min_price ~ month_in, data = booking)

```

```{r}

booking$current_page <- as.factor(booking$current_page)
ggplot(booking, aes(x = current_page, y = min_price, color = current_page)) + 
  geom_boxplot()

```

```{r}

fligner.test(min_price ~ current_page, data = booking)

```

#### 4.3 Aplicación de pruebas estadísticas para comparar los grupos de datos



#### 4.4 Aplicación de funciones lineales para resolución del problema


## 5. REPRESENTACIÓN DE LOS RESULTADOS

A lo largo del documento se han presentado representaciones gráficas de los análisis realizados y de los resultados obtenidos.

## 6. RESOLUCIÓN DEL PROBLEMA
