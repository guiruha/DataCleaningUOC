---
title: 'Práctica 2: Booking Data Cleaning'
author: "Gerard Alcalde and Guillem Rochina"
date: "2022-12-24"
output:
  word_document: default
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(tinytex.verbose = TRUE)
suppressWarnings(library(dplyr))
suppressWarnings(library(ggplot2))
suppressWarnings(library(tidyr))
suppressWarnings(library(lubridate))
suppressWarnings(library(stringr))
suppressWarnings(library(knitr))
suppressWarnings(library(VIM))
suppressWarnings(library(corrplot))
suppressWarnings(library(MASS))
suppressWarnings(library(devtools))
install_github("ProcessMiner/nlcor")
suppressWarnings(library(nlcor))
```

## 1. DESCRIPCIÓN DEL DATASET

### ¿Por qué es importante y qué pregunta/problema pretende responder?

#### 1.1. Descripción general

El conjunto de datos ha tratar es el obtenido como resultado de la práctica anterior de Web Scraping. El dataset presenta los datos e indicadores más relevantes de cada uno de los hoteles encontrados en función de determinados criterios de búsqueda (ciudad, fecha de check-in, fecha de check-out, número de adultos, niños y habitaciones). En este dataset en concreto presentamos datos para distintas fechas (diciembre, marzo y junio), ciudades (barcelona, madrid, valencia), número de adultos, niños y habitaciones a fin de tener una muestra más amplia e informativa que la que nos daría una búsqueda con tan sólo unos parámetros fijos.

A continuación, se realiza una breve descripción de cada una de las variables disponibles antes de realizar la limpieza:

* **Name (str)**: Nombre del hotel.
* **City (str)**: Nombre de la ciudad donde se realiza la búsqueda.
* **Check-in (str)**: Fecha de entrada al hotel.
* **Check-out (str)**: Fecha de salida del hotel.
* **Adults (int)**: Nº de adultos para los que se realiza la reserva.
* **Num_rooms (int)**: Nº de habitaciones reservadas.
* **Address (str)**: Dirección postal del hotel, nombre de calle, barrio de la ciudad, código postal, etc.
* **Hotel_coordinates (str)**: Latitud y longitud de la ubicación del hotel.
* **Hotel_score (int)**: Nota general que recibe el hotel por los usuarios.
* **Hotel_scores (dict)**: Puntuaciones de cada una de las dimensiones que puede valorar un usuario.
* **Hotel description (list)**: Descripción aportada por el propietario del hotel
* **Features (list)**: Lista de servicios añadidos del hotel.
* **Room_data (dict)**: Conjunto de diccionarios que recogen las características de cada una de las habitaciones disponibles en el hotel.
* **Page_count (int)**: Posición en la que ha aparecido el hotel en el buscador.
* **Current_page (int)**: Página en la que ha aparecido el hotel en el buscador.

#### 1.2. Importancia y problema a responder

Aparecer en los primeros resultados de una búsqueda de un usuario por internet se ha convertido en los últimos años en una de las preocupaciones principales de cualquier negocio que busca hacerse un hueco en el mundo digital. Este fenómeno explica la proliferación de herramientas como el SEO y el SEM, mediante las cuales se intenta innovar (más allá del pago de tarifas para aparecer en las primeras páginas de búsqueda) a fin de lograr un mejor “posicionamiento” en buscadores como Google o Bing. El negocio hotelero no es una excepción en este caso.
No obstante, el uso de dichas herramientas no resulta útil si nos enfrentamos a un buscador dentro de una página web, como el caso que nos ocupa con Booking.com. ¿Qué hacer entonces? ¿Cómo mejorar el posicionamiento dentro de la web?
Asimismo, la fijación de precios o “pricing” puede ser una tardea ardua en los últimos años, pues la aparición de apartamentos vacacionales a través de plataformas como AirBnB ha incrementado de manera significativa la competencia a la que se deben enfrentar los propietarios de los hoteles, lo que influye en última instancia los precios a establecer por sus servicios. Dicho esto, ¿Qué precios se deben fijar dadas las características de un hotel? ¿Añadir un servicio adicional permitiría a un hotel elevar los precios de sus habitaciones?.
Ante las preguntas presentadas en los párrafos anteriores, el objetivo de este proyecto es dual. Por un lado se busca obtener las características que hacen que un hotel esté mejor posicionado que otro en el metabuscador de Booking.com y, por el otro, se persigue desarrollar un modelo que indique qué precios se deberían establecer dadas las características de una habitación y qué elementos pueden incrementar el precio de forma relevante.
En conclusión, el presente proyecto pretende dar continuidad a la Práctica 1, explotando los datos que se obtuvieron mediante web scrapping para ayudar a superar dos de los desafíos más relevantes para el sector hotelero.


## 2. LIMPIEZA DE LOS DATOS

A fin de iniciar el proceso de limpieza de datos, en primer lugar, se debe realizar la lectura del fichero csv que obtuvimos en la práctica anterior. Como resultado de la función de R-base “read.csv” obtenemos un objeto data.frame, que manipularemos en la presente sección.

```{r}
# Lectura y breve descripción de los datos

booking <- read.csv("hotels_data.csv", header = TRUE)
summary(booking)
```

Tanto con la función “summary” como con la función “class” nos muestran que a cada variable se le ha asignado o bien la clase de entero o la de string. En concreto, muchas de las variables interpretadas como string se tratan de diccionarios y listas, factor que deberemos tener en cuenta a la hora de trabajar con la limpieza de estas variables.

```{r}
# Tipo de dato asignado a cada variable

res <- sapply(booking, function(x) class(x))
kable(data.frame(var=names(res), clase=as.vector(res)))
```

#### 2.1. Transformación de las variables en el formato adecuado

Como se ha comentado, existen algunas variables que presentan todavía una estructura no válida para tratarlos estadísticamente o introducirlos en un modelo de data mining. En esta sección nos encargamos de tratar dichas columnas a fin de obtener nuevas variables con un formato adecuado, eliminando a su vez cualquier información que no nos sea de utilidad.

En primer lugar, cabe destacar que no todas las columnas que tenemos disponibles en el dataset nos ofrecen información relevante para nuestro problema. Por tanto, a fin de reducir la dimensionalidad de este, nos encargamos de eliminar las columnas con información redundante (name y search_date).

```{r}
# Seleccionamos con la función "select" de dplyr todas las columnas excepto name y search_date, que nos van a ser de poca utilidad.

booking <- booking %>%
  dplyr::select(-c("name", "search_date"))
```

La columna hotel_coordinates incluye tanto los valores de latitud como los de longitud, separados por una coma. Dado que ambos dos valores nos indican información distinta, pues la latitud nos proporcionar información de la posición en dirección norte o sur del ecuador y la longitud información de la posición en dirección este u oeste, en este caso hemos optado por separarlos en dos columnas distintas.

```{r}
# Separamos los valores de la variable hotel coordinates en dos nuevas columnas, latitud y longitud
# La columna hotel_coordinates se elimina en el proceso

booking <- booking %>%
  separate(hotel_coordinates, c("latitude", "longitude"), sep = ",")

booking$latitude <- as.numeric(booking$latitude)
booking$longitude <- as.numeric(booking$longitude)
```

Por su parte, "hotel_scores" alberga diccionarios en cada uno de los registros. Cada diccionario consta del nombre de cada dimensión (caracterísitca a valorar) como clave y la valoración que recibe como valor. Dado que R lo ha interpretado como un string, nuestro enfoque en su limpieza se ha basado en separar la información con comas y, una vez obtenidas todas las columnas resultantes, extraer los datos numéricos de cada registro para quedarnos solo con los scores de cada dimensión.

```{r}
# Definimos un vector con los nombres de las columnas a crear

columns <-  c("staff_score", "facilities_score", "cleanliness_score", "comfort_score", "value_for_money_score", "location_score", "free_wifi_score")

# Separamos los strings (diccionarios) en función de las comas y creamos las columnas correspondientes. La primera columna creada es una NA porque todos los primeros registros en cada diccionario están vacíos (por un fallo en la extracción de datos). Estableciendo la columna como NA, indicamos a la función separate que ignore dichos datos y no cree columna alguna para ellos.

booking <- booking %>%
  separate(hotel_scores, c(NA, "staff_score", "facilities_score", "cleanliness_score", "comfort_score", "value_for_money_score", "location_score", "free_wifi_score"), sep = ",")

# Extraemos los valores numéricos de cada columna con la función del paquete readr, "parse_number"

booking[columns] <- apply(booking[columns], 2, readr::parse_number)
```

Dado que de las fechas tan sólo nos interesa el mes en el que se realiza la reserva (un alojamiento con unas características determinadas podría estar mejor posicionado en un determinado mes que en otro o tener un precio distinto) procedemos a extraer dicha información de las variables check-in y check-out, eliminando estas últimas en el proceso. De hecho, dado que los datos que hemos extraído corresponden al mismo mes en todos los registros, tan sólo nos quedaremos con una columna de mes. Asimismo, no crearemos una columna is_june, pues la dejaremos como caso base, es decir, cuando no sea ninguna de las otras dos opciones (o Diciembre o Marzo).

```{r}
booking <- booking %>%
  # Separamos el nombre del mes del resto de elementos del registro para check_in y check_out. Eliminamos las columnas en el proceso.
  separate(check.in, c(NA, "month", NA), sep = "-") %>%
  # Eliminamos también check-out del dataset
  dplyr::select(-c("check.out")) %>%
  mutate(is_december = ifelse(month == "December", 1, 0),
         is_march = ifelse(month == "March", 1, 0))
```

De la columna address tan sólo nos interesa el código postal (el barrio no se incluye en todos los registros a diferencia del CP, así que hemos optado por quedarnos con estos valores), por lo que extraemos dicha información para crear una nueva columna llamada postal_code, eliminando la información redundante en el proceso.

```{r}
# Hemos tenido que cambiar esta función para que el extract no diera problemas
Sys.setlocale('LC_ALL', 'C')
# Extraemos los valores de codigo postal de la columna addres utilizando expressiones regulares
booking <- booking %>%
  extract(address, c("postal_code"), regex = "( [0-9]{5} )")

```

Los features, entendidos como servicios adicionales más allá de la propia habitación, fueron guardados como una lista. No obstante, de nuevo nos encontramos como R lo ha identificado como string. Es por ello por lo que realizamos un tratamiento similar al de la columna de scores. En este caso creamos tantas variables dummy (columnas dicotómicas con valores de 1, en caso de que el feature exista en dicho registro, o 0, en caso de que no exista) como servicios adicionales de hotel consideramos interesantes.

```{r}
# Definimos las features que consideramos que son interesantes. Utilizamos este formato para filtrar por expresión regular.
feature_list <- c("('Free Wifi')", "('Air conditioning')", "('24-hour front desk')", "('Safe')", "('Heating')", "('Elevator')", "('Private Bathroom')", "('Non-smoking rooms')", "('Aparments')", "('City view')","('Kitchen')", "('Pet Friendly')", "('Swimming pool')", "('Balcony')")

# Creamos un bucle en el que se recorre cada elemento de la lista de features
for (feature in feature_list){
  # Se eliminan los parentésis y comillas de la variable local feature para crear el nombre de la columna.
  col_name <- str_replace(str_replace(str_to_lower(str_extract(feature, "([A-Z][a-z]*( |-)?[A-Z]?[a-z]* ? ?[a-z]*)")), " ", "_"), "-", "_")
  booking <- booking %>%
  # Extraemos el nombre del feature de cada uno de los registros (strings). En caso de que no encuentre ningún valor devuelve un NA.
  extract(features, c(col_name), regex = feature, remove = FALSE) %>%
  # Transformamos la columna que acaba de ser creada para que indique con un 1 si el registro tenia dicho servicio y 0 si el valor era NA (no tenida dicho servicio)
  mutate_(.dots = setNames(list(paste0("as.integer(!is.na(",col_name,"))")), col_name))
}

# Eliminamos la columna de features para finalizar
booking <- booking %>%
  dplyr::select(-c("features"))
```

Por otro lado, nos encontramos con la columna que incluye la descripción del hotel, esta descripción es muy amplia y un análisis profundo de ella requeriría de técnicas de NLP que no son el objetivo de esta práctica. No obstante, consideramos que la longitud de la descripción del hotel sí que puede tener una relación con la posición en el buscador, por lo que transformaremos esta variable a una nueva variable que contenga el número total de palabras que contiene la descripción, eliminando de nuevo dicha columna en el proceso.

```{r}
# Evaluamos la longitud de la descripción del hotel
booking$length_description <- lengths(gregexpr("\\W+", booking$hotel_description)) + 1

# Eliminamos la columna hotel_description
booking <- booking %>%
    dplyr::select(-c("hotel_description"))
```

Finalmente, en la columna Room_data, se incluye mucha información referente a los tipos de habitaciones disponibles, precios, características, etc. Esta se había extraído de esta forma con el objetivo de procesarla mediante un diccionario de Python. No obstante, al haber optado por un procesado con R este se complicará un poco más. En esta columna tenemos distintos datos que pueden ser muy relevantes, de los cuales extraeremos los siguientes:
•	min_price: Precio de la habitación más económica.
•	max_price: Precio medio de las habitaciones del hotel.
•	suite_available: Una de las habitaciones es de tipo suite.
•	apartment_available: Una de las habitaciones es de tipo apartamento.
•	free_cancelation_available: Alguna de las habitaciones tiene cancelación gratuita.

```{r}
# Función que encuentra el precio mínimo de la habitación dado un string con la información de las habitaciones
find_min_price <- function(text) {
  if (text=="{}"){
    return(NA)
  }
  a <- gregexpr("([0-9]*', 'room_capacity)", text)
  
  min_price <- NA
  for (value in a[[1]]){
    substring <- substr(text, value, value+20)
    price <- as.numeric(strsplit(substring, "'")[[1]][1])
    if (is.na(min_price)) {
      min_price <- price
    }
    
    if (price < min_price) {
      min_price <- price
    } 
  }
  if (min_price == 0){
    return(NA)
  }
  else {
    return(min_price)
  }
}

# Aplicamos la función a todos los valores
min_price_vector <- c()
for (i in seq(1, length(booking$room_data))) {
  min_price_vector <- append(min_price_vector, find_min_price(booking$room_data[i]))
}

# Guardamos los resultados en una nueva columna.
booking$min_price <- min_price_vector

# Función que encuentra el precio máximo de la habitación dado un string con la información de las habitaciones
find_max_price <- function(text) {
  if (text=="{}"){
    return(NA)
  }
  a <- gregexpr("([0-9]*', 'room_capacity)", text)
  
  max_price <- NA
  for (value in a[[1]]){
    substring <- substr(text, value, value+20)
    price <- as.numeric(strsplit(substring, "'")[[1]][1])
    if (is.na(max_price)) {
      max_price <- price
    }
    
    if (price > max_price) {
      max_price <- price
    } 
  }
  if (max_price == 0){
    return(NA)
  }
  else {
    return(max_price)
  }
}

# Aplicamos la función a todos los valores
max_price_vector <- c()
for (i in seq(1, length(booking$room_data))) {
  max_price_vector <- append(max_price_vector, find_max_price(booking$room_data[i]))
}

# Guardamos los resultados en una nueva columna.
booking$max_price <- max_price_vector

# Buscamos si hay una habitación en suite
is_suite_vector <- c()
for (i in seq(1, length(booking$room_data))) {
  is_suite <- gregexpr("(suite)", booking$room_data[i])[[1]][1]
  
  if (is_suite==-1) {
    is_suite_vector <- append(is_suite_vector, 0)
  } else {
    is_suite_vector <- append(is_suite_vector, 1)
  }
}

# Guardamos los resultados en una nueva columna.
booking$is_suite <- is_suite_vector

# Buscamos si hay opción de apartamento
is_apartment_vector <- c()
for (i in seq(1, length(booking$room_data))) {
  is_apartment <- gregexpr("(Apartment)", booking$room_data[i])[[1]][1]
  
  if (is_apartment==-1) {
    is_apartment_vector <- append(is_apartment_vector, 0)
  } else {
    is_apartment_vector <- append(is_apartment_vector, 1)
  }
}

# Guardamos los resultados en una nueva columna.
booking$is_apartment <- is_apartment_vector

# Buscamos si tiene cancelación gratuita
free_cancelation_vector <- c()
for (i in seq(1, length(booking$room_data))) {
  free_cancelation <- gregexpr("(Free cancellation)", booking$room_data[i])[[1]][1]
  
  if (free_cancelation==-1) {
    free_cancelation_vector <- append(free_cancelation_vector, 0)
  } else {
    free_cancelation_vector <- append(free_cancelation_vector, 1)
  }
}

# Guardamos los resultados en una nueva columna.
booking$has_free_cancelation <- free_cancelation_vector

# Eliminamos la columna correspondiente a room_data
booking <- booking %>%
  dplyr::select(-c("room_data"))

```


#### 2.2. Ceros y elementos vacíos

Dando paso a el tratamiento de ceros y elementos vacios, lo primero que debemos hacer es identificar aquellas variables en las que encontramos valores faltantes. Como observamos, "postal_code" (19), "longitude" (16), "hotel_score" (8), min (45) y max_price (17) y el resto de variables relacionadas con los scores (60) presentan valores faltantes, destacando free_wifi_score con 423 registros faltantes, consecuencia con toda seguridad de la ausencia de este servicio en dichos hoteles.

```{r}
sapply(booking, function(y) sum(length(which(is.na(y)))))
  
```

Por lo que respecta a la variable "postal_code" encontramos que en todos aquellos registros donde se encuentan NAs, también hallamos datos faltantes en la mayoría del resto de columnas. Por tanto, dado que dichos registros no nos aportan información de valor, procedemos a eliminarlos del dataset.

```{r}

# Comprobamos algunos de los registros donde hay datos faltantes de postal_code
booking[is.na(booking$postal_code),] %>%
  dplyr::select(c("city", "month", "postal_code", "longitude", "hotel_score", "staff_score")) %>%
  head(3)

# Filtramos los datos para eliminar aquellos registros que tienen NAs en postal_code
booking <- booking[!is.na(booking$postal_code),]
  
```

Si comprobamos de nuevo que columnas presentan todavía datos faltantes, observamos que en algunos casos (como "longitude") hemos logrado eliminar todos los datos faltantes, mientras que en el resto se han reducido en 16 unidades el número de registros con NAs, pues como se había comentado todos aquellos registros con ausencia de postal_code, también carecía del resto de datos.

```{r}
sapply(booking, function(y) sum(is.na(y)))
```

A continuación, analizamos los datos faltantes de hotel_score. En este caso, encontramos que la ausencia de datos se registra de dos formas distintas, o bien con la introducción de NAs o bien con el valor -1. Por tanto, dado que el tratamiento en ambos casos va a ser el mismo, transformamos todos los valores -1 en NAs para poder llevar a cabo el siguiente proceso de inputación.

```{r}

# Comprobamos algunos de los registros donde hay datos faltantes de hotel_score
booking[is.na(booking$hotel_score),] %>%
  dplyr::select(c("city", "month", "hotel_score", "staff_score", "location_score", "longitude", "facilities_score", "cleanliness_score", "comfort_score")) %>%
  head(5)

```

```{r}

# Comprobamos algunos de los registros donde hay datos faltantes de hotel_score
booking[booking$hotel_score == "-1",] %>%
  dplyr::select(c("city", "month", "hotel_score", "staff_score", "location_score", "longitude", "facilities_score", "cleanliness_score", "comfort_score")) %>%
  tail(5)

booking[booking$hotel_score == "-1",] %>%
  dplyr::select(c("city", "month", "hotel_score", "staff_score", "free_wifi_score", "free_wifi")) %>%
  tail(10)


# Tranformamos los valores -1 en NAs para poder llevar a cabo el proceso de inputación correctamente.
booking$hotel_score <- ifelse(booking$hotel_score == "-1", NA, booking$hotel_score)

```

Dado que en este caso tan sólo encontramos datos faltantes en las columnas de score no consideramos eliminar estos registros, sino llevar a cabo una imputación. Aunque se podría haber utilizado una metología más simple como el uso de la media o la mediana, hemos optado por hacer uso de un método más complejo, basado en la similitud entre registros, en concreto llevar a cabo una imputación mediante el algoritmo de K vecinos más próximos. En este caso, la función se encarga de devolver los mismos valores en caso de que ya existan en el dataset y el valor de los registros más "similares" en el caso de un registro con NAs. No obstante, en el caso de "free_wifi_score" tan sólo introduciremos el valor de 0 en aquellos datos con ausencia de valores, pues tras analizar más en detenimiento los registros, aquellos con datos faltantes de free_wifi_score tienen un valor igual a 0 en la columna free_wifi, lo que nos indica ausencia de este servicio en el hotel.

```{r}

# Imputamos los datos con K Neirest Neighbours
booking$hotel_score <- kNN(booking)$hotel_score
booking$staff_score <- kNN(booking)$staff_score 
booking$facilities_score <- kNN(booking)$facilities_score
booking$cleanliness_score <- kNN(booking)$cleanliness_score
booking$comfort_score <- kNN(booking)$comfort_score
booking$value_for_money_score <- kNN(booking)$value_for_money_score
booking$location_score <- kNN(booking)$location_score
# Imputamos valores de 0 a la columan free_wifi_score
booking$free_wifi_score <- ifelse(is.na(booking$free_wifi_score), 0, booking$free_wifi_score)

```

En el caso de los precios, encontramos NAs en aquellos registros que presentaban valores iguales a 0 (no son valores lógicos). En este caso también encontramos que los únicos valores faltantes en estos registros corresponde a precio, por lo que procedemos de la misma forma que con los scores.

```{r}

booking[is.na(booking$min_price),] %>%
  dplyr::select(c("city", "month", "hotel_score", "max_price", "min_price")) %>%
  tail(10)

```

```{r}

# Imputamos los datos con K Neirest Neighbours
booking$max_price <- kNN(booking)$max_price
booking$min_price <- kNN(booking)$min_price 

```

Una última comprobación nos revela que el dataset ya no cuenta con datos faltantes, con independencia del formato que pudieran presenta (strings vacías, valores de -1 en integers, o simplemente NAs).

```{r}
sapply(booking, function(y) sum(is.na(y)))
```

```{r}

sapply(booking, function(y) sum(y == ""))

```

#### 2.3. Valores extremos

Los outliers son aquellos datos extremos que dada su distancia con respecto al grueso de la distribución a priori resultan no ser congruentes si los comparamos con la población/muestra analizada. Existen varias vías para detectarlos, no obstante el método más rápdio y común se basa en el uso de boxplots, donde se detectan aquellos valores que se sitúan 1.5 veces más allá del rango intercuartílico con respecto a la mediana. Asimismo, en este trabajo también haremos uso de la función "boxplots.stats()" a fin de detectar, con un output más allá del visual, los outliers que encontramos usando boxplots. Dado que muchas de las variables que hemos generado en la fase de limpieza son dicotómicas, tan solo nos encargaremos de comprobar si existen valores extremos en las columnas de **num_rooms**, **latitude**, **longitude**, **hotel_score** y el resto de **scores del hotel**, **length_description**, **min_price** y **max_price**.


```{r}

ggplot(booking, aes(y = num_rooms, color = city))+
  geom_boxplot() +
  facet_grid(~city)

boxplot.stats(booking$num_rooms)$out

```

Empezamos analizando el número de habitaciones y observamos que en las 3 ciudades el número oscila entre 2 y 3 habitaciones para las búsquedas realizadas, lo cual son números razonables, aunque en Valencia esta aparezca como un outlier. Por lo tanto, aceptamos los valores outliers observados en la ciudad de Valencia como valores correctos.

A continuación se analiza la ubicación de los hoteles mediante su longitud y latitud.


```{r}

ggplot(booking, aes(y = latitude, color = city))+
  geom_boxplot() +
  facet_grid(~city)

boxplot.stats(booking$latitude)$out

```

Observamos que la latitud contiene valores distintos para cada ciudad, como es de esperar al tener cada una una ubicación distinta. En el caso de Valencia vemos una mayor dispersión y tenemos la presencia de algunos outliers, esto es debido a que probablemente, al ser una ciudad más pequeña que Madrid o Barcelona tenga una menor disponibilidad hotelera y algunos de los hoteles hayados no pertenezcan a Valencia ciudad sino a los alrededores de esta.

A continuación evaluaremos si obtenemos un comportamiento similar con la longitud.

```{r}

ggplot(booking, aes(y = longitude, color = city))+
  geom_boxplot() +
  facet_grid(~city)

boxplot.stats(booking$longitude)$out

```

Para la longitud obtenemos unos resultados parecidos en los que hay una menor dispersión en los outliers de Valencia. Dado que estas variaciones tan pequeñas que se observan en los resultados son razonables aceptamos los resultados como validos.

A continuación se evalúan las distintas puntuaciones del hotel. 

```{r}

ggplot(booking, aes(y = hotel_score, color = city))+
  geom_boxplot() +
  facet_grid(~city)

boxplot.stats(booking$hotel_score)$out

```

Por un lado observamos que la puntuación general del hotel oscila entre el 8 y el 9 siendo mayor en Madrid que en Barcelona o Valencia. También nos encontramos que hay outliers en las 3 ciudades no obstante todos se hayan en una puntuación entre el 5 y el 10, cuando el rango factible es entre 0 y 10, por lo que pueden ser valores anómalos de hoteles que han obtenido una puntuación más baja de lo normal, pero no por ello deben ser descartados.

A continuación, evaluamos aquellos hoteles que han obtenido una nota o muy baja o excepcionalmente buena para verificar que los resultados sean coherentes.

```{r}

booking %>%
  filter(hotel_score <= 7.0) %>%
  dplyr::select(c("hotel_score", "facilities_score", "cleanliness_score", "location_score")) %>%
  sample_n(5)

```

Se observa que los hoteles con una mala puntuación lo hacen en la mayoría de sus características, lo que corrobora los resultados obtenidos y no es una sección que ha penalizado a los resultados obtenidos.

```{r}

booking %>%
  filter(hotel_score == 10.0) %>%
  sample_n(3)

```

Los hoteles con una puntuación de 10 destacan por obtener esta puntuación en todos los aspectos y tienen unas descripciones relativamente cortas, los precios mínimos y los máximos son muy distantes lo que sorprende. Dado que solo corresponde a 3 registros y que los resultados son razonables, puede corresponder a un hotel nuevo con muy pocas valoraciones, lo que permitiría una nota excepcionalmente alta otorgada por unos pocos clientes.


A continuación, se evalúan las instalaciones del hotel.

```{r}

ggplot(booking, aes(y = facilities_score, color = city))+
  geom_boxplot() +
  facet_grid(~city)

boxplot.stats(booking$facilities_score)$out

```

Vemos que los resultados obtenidos continuan en la línea anterior con algunos outliers en Barcelona o Valencia, pero con resultados lógicos.

A continuación evaluamos aquellos hoteles que han obtenido una nota inferior al 6.5 para identificar si se trata de un error o no.

```{r}

booking %>%
  filter(facilities_score <= 6.5) %>%
  sample_n(3)

```

Observamos que los hoteles parecen tener unas características consistentes y que la extracción de características ha sido correcta por lo que no podemos atribuir los resultados a un error sino meramente a una baja calidad del hotel.

```{r}

ggplot(booking, aes(y = staff_score, color = city))+
  geom_boxplot() +
  facet_grid(~city)

boxplot.stats(booking$staff_score)$out

```

Para la puntuación otorgada a los trabajadores del hotel obtenemos unos resultados similares a los previos, con la diferencia de que en este apartado la puntuación promedio es más elevada rondando el 9 en las 3 ciudades y todas presentan outliers con valores inferiores.

Evaluamos aquellos resultados con puntuaciones muy bajas.

```{r}

booking %>%
  filter(staff_score <= 6.7) %>%
  sample_n(3)

```

De los resultados obtenidos sorprende uno en Valencia que tiene unas puntuaciones muy elevadas excepto en **staff_score** la cual es bastante baja. Si nos fijamos estas puntuaciones son muy exactas (10.0, 9.0, 7.5 o 5.0) lo cual puede venir dado por un número de puntuaciones muy reducidas en las que un cliente ha puntuado de forma muy negativa este aspecto. No por ello eliminaremos el registro o lo modificaremos ya que es razonable el resultado, y afectará en la posición que presenta el hotel en el buscador.

A continuación se evalúa la limpieza del hotel.

```{r}

ggplot(booking, aes(y = cleanliness_score, color = city))+
  geom_boxplot() +
  facet_grid(~city)

boxplot.stats(booking$cleanliness_score)$out

```

Observamos unos resultados muy similares a los anteriores. Para descartar algún error observamos aquellos registros con puntuaciones excepcionalmente bajas.

```{r}

booking %>%
  filter(cleanliness_score < 7.0) %>%
  sample_n(3)

```

Vemos un comportamiento razonable en estos hoteles, por lo que, siendo resultados razonables, aceptamos estos valores outliers.

A continuación, se valora la puntuación de la comodidad.

```{r}

ggplot(booking, aes(y = comfort_score, color = city))+
  geom_boxplot() +
  facet_grid(~city)

boxplot.stats(booking$comfort_score)$out

```

```{r}

booking %>%
  filter(comfort_score < 7.0) %>%
  sample_n(3)

```

```{r}

ggplot(booking, aes(y = value_for_money_score, color = city))+
  geom_boxplot() +
  facet_grid(~city)

boxplot.stats(booking$value_for_money_score)$out

```

```{r}

booking %>%
  filter(value_for_money_score <= 7.0) %>%
  sample_n(3)

```

```{r}

ggplot(booking, aes(y = location_score, color = city))+
  geom_boxplot() +
  facet_grid(~city)

boxplot.stats(booking$location_score)$out

```

```{r}

booking %>%
  filter(location_score < 7.0) %>%
  sample_n(3)

```

```{r}

ggplot(booking, aes(y = free_wifi_score, color = city))+
  geom_boxplot() +
  facet_grid(~city)

boxplot.stats(booking$free_wifi_score)$out

```

```{r}

booking %>%
  filter(free_wifi_score < 5.0 & free_wifi_score > 0) %>%
  sample_n(3)

```


A continuación se evalúa la longitud de las descripciones.

```{r}

ggplot(booking, aes(y = length_description, color = city))+
  geom_boxplot() +
  facet_grid(~city)

boxplot.stats(booking$length_description)$out

```


Observamos que las descripciones tienen una longitud muy similar en las 3 ciudades en torno a las 120-170 palabras, presentando algún outlier por la parte superior, pero siempre con descripciones inferiores a las 400 palabras. Aunque corresponda a una descripción un poco extensa, no parece que corresponda a un outlier sino simplemente a una descripción más extensa de lo habitual.

A continuación evaluaremos el precio mínimo de las habitaciones del hotel.

```{r}

ggplot(booking, aes(y = min_price, color = city))+
  geom_boxplot() +
  facet_grid(~city)

boxplot.stats(booking$min_price)$out

```

Observamos que el precio mínimo tiene una gran disparidad oscilando de promedio entre los 100€ y los 500€, siendo Valencia la ciudad con el menor rango intercuartil con presencia de outliers en el rango superior de precios, con alguna habitación con precios cercanos a los 1000€, que aunque puedan parecer caros, son razonables en algún hotel de lujo de la ciudad.

A continuación se evalúan los precios máximos.

```{r}

ggplot(booking, aes(y = max_price, color = city))+
  geom_boxplot() +
  facet_grid(~city)

boxplot.stats(booking$min_price)$out

```

Observamos unos precios promedio mucho más elevados con un mayor rango intercuartil en la ciudad de Valencia, lo que sorprende al ser lo contrario que con los precios mínimos. También se observa que los outliers en este caso aparecen por el lado inferior especialmente en la ciudad de Madrid, aunque con precios positivos, que podrían corresponder a hoteles muy económicos o albergues.

Por otro lado sorprende ver que los precios máximos no superan el valor máximo observado en el precio mínimo, lo que se puede atribuir a que aquellos hoteles con precios muy elevados no ofrecían una variedad de habitaciones y precios.


#### 2.4. Exportación de los datos postprocesados

Una vez se han procesado los datos, se exportaran a un fichero CSV.

```{r}

write.csv(booking, "hotel_data_processed.csv")

```

## 3. INTEGRACIÓN Y SELECCIÓN

En primer lugar, hemos obtado por añadir datos de vuelos por varias razones:

* Un mayor número de vuelos en un mes podría aumentar las búsquedas de hoteles cerca del aeropuerto.
* Un mayor número de vuelos en un mes indica más turismo internacional (en lugar de sólo turismo nacional). Un tipo de turismo que podría estar buscando hoteles con características diferentes a los turistas nacionales.
* Un mayor número de vuelos en un mes indica más turismo general, lo que puede influir en las estrategias de promoción y ofertas de determinados hoteles, influyendo en última instancia en su posición en el buscador Booking.

```{r}
# Leemos los datos de vuelos
flights <- read.csv("avia_tf_apal_linear.csv.gz")
summary(flights)
```

Para añadir dicha información hacemos un tratamiento de los datos obtenidos en Eurostat a fin de obtener una media de vuelos por mes para los últimos 5 años. Una vez obtenidos, tan solo debemos hacer un merge con nuestro dataset original.

```{r}
proc_flights <- flights %>% 
        # Filtramos para quedarnos solo con los aeropuertos de interés
        # Código OACI/ICAO: Barcelona --> ES_LEBL; Valencia --> ES_LEVC; Madrid: ES_LEMD
        filter(rep_airp %in% c("ES_LEBL", "ES_LEVC", "ES_LEMD")) %>% 
        # Filtramos para quedarnos solo con los datos de carga de pasajeros
        filter(tra_meas == "PAS_CRD") %>%
        # Nos interesa solo los datos mensuales, así que filtramos por ellos
        filter(freq == "M") %>%
        separate(TIME_PERIOD, c("YEAR", "MONTH"), sep = "-") %>%
        # Nos quedamos solo con los últimos 5 años y los meses de Marzo, Junio y Diciembre
        filter(YEAR %in% c("2022", "2021", "2020", "2019", "2018") & MONTH %in% c("03", "06", "12")) %>%
        # No nos interesa los datos por aerolínea, solo los generales
        filter(airline == "TOTAL") %>%
        # Modificamos la columna de MONTH para tener los nombres del mes y cambiamos el código del aeropuerto por el nombre de la ciudad
        mutate(month_name = ifelse(MONTH == "03", "March", ifelse(MONTH == "06", "June", "December")),
               city_airp = ifelse(rep_airp == "ES_LEBL", "Barcelona", ifelse(rep_airp == "ES_LEVC", "Valencia", "Madrid"))) %>%
        # Agrupamos por ciudad y mes y calculamos la media de vuelos.
        group_by(rep_airp, month_name) %>%
        mutate(mean_flights = mean(OBS_VALUE)) %>%
        ungroup() %>%
        dplyr::select(c(city_airp, month_name, mean_flights))

# Nos quedamos con los registros únicos
final_flights <- unique(proc_flights)

# Hacemos un merge con bookings
booking <- booking %>%
  merge(final_flights, by.x = c("city", "month"), by.y = c("city_airp", "month_name"))
```


## 4. ANÁLISIS DE LOS DATOS

En este apartado se procede a analizar los datos que previamente hemos preprocesado. El objetivo de este trabajo era obtener que factores influenciaban en el posicionamiento de un hotel en el buscador de Booking, para ello se recogieron distintas variables mediante webscrapping, las cuales se han almacenado y preprocesado en el dataframe **booking**.

A continuación se evaluará la influencia de las distintas variables sobre la posición de un hotel en el buscador, para ello se emplea una matriz de correlación. Una vez obtenidas las variables con mayor correlación con la variable objetivo generaremos una selección de los grupos de datos a analizar, separando los datos según los valores de estas variables correlacionadas con la variable objetivo.

Una vez generados los distintos grupos procederemos a evaluar la normalidad y la homogeneidad de la varianza para así poder determinar en el siguiente punto que pruebas estadísticas se pueden aplicar.

Finalmente aplicaremos distintas pruebas estadísticas adicionales a la correlación hayada inicialmente. Estas pruebas estadísticas incluirán contrastes de hipótesis y regresiones lineales.

#### 4.1 Correlación con la variable objetivo y selección de los grupos de datos que se quieren analizar

Comenzamos evaluando la correlación entre las distintas variables con nuestra variable objetivo, para ello creamos una matriz de correlación y evaluamos los resultados obtenidos.

```{r}
# Transformamos las variables a numérico
booking$postal_code <- as.numeric(booking$postal_code)
booking$latitude <- as.numeric(booking$latitude)
booking$longitude <- as.numeric(booking$longitude)
booking$free_wifi <- as.numeric(booking$free_wifi)
#booking$apartments <- as.numeric(booking$apartments)
#booking$pet_friendly <- as.numeric(booking$pet_friendly)

# Seleccionamos solo las variables numéricas
booking_numeric <- booking %>%
  dplyr::select(-c("city", "month", "as.integer(!is.na(NA))"))

mattmp <- booking_numeric %>%
  dplyr::select(c("adults", "children", "num_rooms", "postal_code", "latitude", "longitude", "hotel_score", "length_description", 
           "is_suite", "is_apartment", "has_free_cancelation", "min_price","max_price", "current_page", "in_page_count", "page_count"))

sapply(mattmp, function(y) sum(is.na(y)))

# Creamos una matriz de correlación del dataset
cor_mat <- cor(mattmp, method = "spearman")
plot.new()
plot.window(xlim=c(-2,2), ylim=c(5,10))
corrplot(cor_mat, method="color", type = "lower", tl.col = "black", tl.srt = 45, diag = FALSE, tl.cex = 0.55, addCoef.col = 'black', number.cex = 0.5)
```
```{r}
mattmp <- booking_numeric %>%
  dplyr::select(c("hotel_score", "staff_score", "facilities_score", "cleanliness_score", "comfort_score", "value_for_money_score", "location_score",
           "mean_flights", "free_wifi_score", "is_december", "is_march", "min_price", "max_price", "current_page", "in_page_count", "page_count"))

sapply(mattmp, function(y) sum(is.na(y)))

# Creamos una matriz de correlación del dataset
cor_mat <- cor(mattmp, method = "spearman")
plot.new()
plot.window(xlim=c(-2,2), ylim=c(5,10))
corrplot(cor_mat, method="color", type = "lower", tl.col = "black", tl.srt = 45, diag = FALSE, tl.cex = 0.55, addCoef.col = 'black', number.cex = 0.5)
```

```{r}
mattmp <- booking_numeric %>%
  dplyr::select(c("balcony", "swimming_pool", "pet_friendly", "kitchen", "city_view", "aparments", "non_smoking_rooms", "hotel_score", 
           "private_bathroom", "elevator", "heating", "safe", "air_conditioning", "free_wifi", "max_price", "min_price", "current_page", "in_page_count", "page_count"))

sapply(mattmp, function(y) sum(is.na(y)))

# Creamos una matriz de correlación del dataset
cor_mat <- cor(mattmp, method = "spearman")
plot.new()
plot.window(xlim=c(-2,2), ylim=c(5,10))
corrplot(cor_mat, method="color", type = "lower", tl.col = "black", tl.srt = 45, diag = FALSE, tl.cex = 0.55, addCoef.col = 'black', number.cex = 0.5)
```

Como bien se puede observar en las matrices, las varialbes que recogen las distintas puntuaciones estan correlacionadas entre ellas, por lo que un hotel que haya obtenido una puntuación elevada en un aspecto generalmente también lo obtendrá en el resto. Este factor es de especial interés si se seleccionan varias columnas de este tipo, pues corremos el riesgo de sufrir un problema de multicolinealidad. También encontramos que los hoteles con distintas atributos como aire acondicionado o baño privado suelen tener el resto de servicios adicionales, aunque este factor puede deberse a que es más habitual encontrar este tipo de elementos en una habitación de hotel, por lo que es común que cuando exista una habitación con calefacción, por ejemplo, también tenga aire acondicionado o baños privado. Por último, aunque es evidente, cabe destacar que las mayores colinealidades las tenemos con variables directamente relacionadas o que presentan información de la misma fuente (current_page con page_count o max_price con min_price). No obstante, esto no es un problema, pues eliminaremos estas variables del conjunto de entrenamiento para no incurrir en "data leakage".

```{r}
# Filtramos para obtener cuales son las variables más correlacionadas con nuestra variable objetivo, current_page
cor_mat <- cor(booking_numeric, method = "spearman")
cor_mat_df <- as.data.frame(cor_mat)
cor_mat_df %>%
  filter(abs(page_count) > 0.065) %>%
  filter(page_count < 0.95) %>%
  arrange(page_count) %>%
  dplyr::select(page_count)
```

No obstante cuando evaluamos la posición en la página web observamos que no hay una correlación elevada con ninguna variable, encontrando valores por debajo de 0.12 (en valor absoluto) para todos los casos. No obstante, para el caso de page_count, hemos optado por someter a estudio aquellas variables que presentan mayor correlación de spearman con la variable dependiente (pues evaluando con distintas métricas que buscan determinar el nivel de dependencia no-lineal hemos obtenido resultados similares). Las variables seleccionadas en cuestión son:

* **kitchen**
* **is_apartment**
* **adults**
* **air_conditioning**
* **elevator**
* **private_bathroom**
* **num_rooms**
* **value_for_money_score**
* **heating**
* **non_smoking_rooms**
* **comfort_score**
* **hotel_score**
* **longitude**
* **has_free_cancelation**

Mientras que la variable dependiente será **page_count**

```{r}
booking_pcount <- booking_numeric %>%
  dplyr::select(c("kitchen", "is_apartment", "adults", "air_conditioning", "elevator", "private_bathroom",
           "num_rooms", "value_for_money_score", "heating", "non_smoking_rooms", "comfort_score", "hotel_score",
           "longitude", "has_free_cancelation", "page_count"))
```

En el caso del problema a resolver relacionado con el precio, al analizar las correlaciones sí que encontramos valores entre 0.15 y 0.20. Aunque estas correlaciones no sean muy elevadas nos ofrecen un escenario más prometedor que el anteriormente presentado. A continuación, procedemos a seguir con el mismo procedimiento que con page_count, esta vez seleccionando las siguientes variables:

* **postal_code**
* **elevator**
* **heating**
* **cleanliness_score**
* **latitude**
* **mean_flights**
* **location_score**
* **hotel_score**
* **facilities_score**
* **non_smoking_rooms**
* **comfort_score**
* **is_apartment**
* **private_bathroom**
* **kitchen**
* **air_conditioning**

```{r}

# Filtramos para obtener cuales son las variables más correlacionadas con nuestra variable objetivo, page_count
cor_mat <- cor(booking_numeric, method = "spearman")
cor_mat_df <- as.data.frame(cor_mat)
cor_mat_df %>%
  filter(abs(max_price) > 0.1) %>%
  filter(max_price < 0.95) %>%
  arrange(max_price) %>%
  dplyr::select(max_price)

booking_price <- booking_numeric %>%
  dplyr::select(c("postal_code", "balcony", "latitude", "air_conditioning", "private_bathroom", "staff_score", "swimming_pool",
                  "location_score", "non_smoking_rooms", "mean_flights", "length_description", "facilities_score", "hotel_score",
                  "safe", "cleanliness_score", "comfort_score", "max_price"))
```

#### 4.2 Comprobación de la normalidad y homogeneidad de la varianza

Para comprobar si los valores de las variables de nuestro dataset se distribuyen o se aproximan a un población distribuida normalmente haremos un análisis visual, con QQ-Plots y Histogramas, y un análisis mediante el test Shapiro-Wilk.

```{r}

norm_cols <- c("value_for_money_score", "comfort_score", "hotel_score", "staff_score", "cleanliness_score", "location_score", "facilities_score", "length_description", "min_price", "max_price")

booking_norm <- booking_numeric %>%
  dplyr::select(norm_cols)

par(mfrow=c(2,2))
for(i in 1:ncol(booking_norm)){
  qqnorm(booking_norm[,i], main = paste("QQ-Plot de",colnames(booking_norm)[i]), col = "navy")
  qqline(booking_norm[,i], col = "red")
  hist(booking_norm[,i], main = paste("Histograma de", colnames(booking_norm)[i]), xlab=colnames(booking_norm)[i], freq = FALSE)
}
```

Los QQ-plots y los histogramas nos muestran una distribuciones con una evidente asimetría negativa en la mayoría de los casos (excepto variables como length_description que muestran una asimetría más bien positiva, aunque podría ser influencia de un dato extremo que no ha sido considerado outlier), así como un evidente problema con las colas, pues en la mayoría de los casos los puntos se alejan de la línea roja, la cual corresponde a la hipotética distribución normal. Por tanto, a priori podríamos rechazar la hipótesis de normalidad de las variables. No obstante, tras ejecutar el test Shapiro-Wilk confirmamos de forma más fiable nuestras primeras conclusiones, pues todos los p-valores muestran valores muy inferiores a 0.05, rechazando en todos los casos la hipótesis nula sobre la normamlidad de los datos.

```{r}

lapply(booking_norm, shapiro.test)

```

A fin de aproximar más los datos a una distribución normal, se propone hacer una transformación de box-cox y comprobar si los datos efectivamente se aproximan más a una normal. Tras llevar a cabo este proceso, si bien los histogramas muestran en algunos casos una distribución "visualmente más normales" y los QQ-plots parecen mostrar que la transformación ha aliviado ligeramente el problema con las colas, los resultados de la transformación no han sido suficientes como para poder considerar que los datos se distribuyen como una normal. No obstante, no debemos preocuparnos demasiado por este problema, pues tenemos suficientes registros como para poder apoyarnos en el Teorema del Límite Central. Por ejemplo, el t-test asume que las medias de las diferentes muestras se distribuyen normalmente (siendo una muestra de más de 30 registros suficiente, como rule of thumb, para que el t-test sea válido aunque los datos no se distribuyan normalmente).

```{r}

par(mfrow=c(2,3))
for(i in 1:ncol(booking_norm)){
  b <- boxcox(lm(booking_norm[,i] ~ 1))
  lambda <- b$x[which.max(b$y)]
  qqnorm((booking_norm[,i]^lambda - 1)/lambda, main = paste("QQ-Plot de",colnames(booking_norm)[i]), col = "navy")
  qqline((booking_norm[,i]^lambda - 1)/lambda, col = "red")
  hist((booking_norm[,i]^lambda - 1)/lambda, main = paste("Histograma de", colnames(booking_norm)[i]), xlab=colnames(booking_norm)[i], freq = FALSE)
}

```

Seguidamente, analizaremos la homocedasticidad mediante boxplots y varios test de homocedasticidad, o de homogeneidad de varianzas. En este caso, no podemos utilizar el test de Levene ni el de Barlett ya que son muy sensibles ante datos no normales y, como acabamos de presentar, los datos analizados no se aproximan en ningún caso a una normal.


PARA VER A QUÉ VARIABLES HAGO EL TEST TENGO QUE VER QUE TEST APLICAS EN LA SIGUIENTE PARTE GERARD.


```{r}

ggplot(booking, aes(x = page_count, y = min_price, color = city)) + 
  geom_point()
  

```

```{r}

fligner.test(min_price ~ city, data = booking)

```

```{r}

ggplot(booking, aes(x = page_count, y = min_price, color = month)) + 
  geom_point()

```

```{r}

fligner.test(max_price ~ month, data = booking)

```

```{r}

booking$current_page <- as.factor(booking$current_page)
ggplot(booking, aes(x = page_count, y = min_price, color = current_page)) + 
  geom_point()

```

```{r}

fligner.test(min_price ~ current_page, data = booking)

```

#### 4.3 Aplicación de pruebas estadísticas para comparar los grupos de datos
En este apartado se aplicarán distintas pruebas estadísticas para comparar los distintos grupos de datos de los que disponemos y ver cual es su relación con la variable objetivo. Esto nos permitirá evaluar que variables tienen un impacto significativo sobre la variable objetivo y cuales no.
Nuestra variable objetivo es la posición en la página (page_count) y relacionada directamente la página en la que aparece (current_page), por lo que las distintas hipótesis que se plantean están asociadas con la influencia de distintas variables sobre el posicinamiento de un hotel en Booking. A continuación se recogen unas hipótesis, aunque sería posible evaluar otras, que también pareciesen interesantes, dado el carácter académico de este trabajo nos centraremos exclusivamente en estudiar la influencia de las variables:

* **free_wifi**
* **has_free_cancelation**
* **hotel_score**
* **min_price**

Las hipótesis que trataremos de verificar serán las siguientes:

* Aquellos hoteles con wifi tendrán una mejor posición (page_count inferior) a los que no dispongan de wifi
* Los hoteles con cancelación gratuita tendrán una posición diferente a los que no dispongan de esta.
* Los hoteles con una puntuación global superior a un 9 tendrán un mejor posicionamiento.
* Los hoteles con un precio mínimo inferior a la media tendrán un mejor posicionamiento.

A continuación se estudiará cada una de estas hipótesis y el resultado obtenido.

**Hipótesis 1**
La primera hipótesis evalúa la influencia del wifi en el posicionamiento del hotel, suponiendo que un hotel con wifi gratuito tendrá un posicionamiento mejor, es decir menor **page_count** que un hotel que no disponga de wifi gratuito. A continuación se plantea la hipótesis nula ($H_{0}$) y la alternativa ($H_{1}$).


* $H_{0}:$ La posición global de un hotel con wifi gratuito y uno sin serán iguales.
* $H_{1}:$ La posición global de un hotel con wifi gratuito será mejor (inferior) a la de uno sin.

TEST NO PARAMETRICO AL NO PODER ASUMIR LA NORMALIDAD DE LOS DATOS

**Hipótesis 2**
Esta segunda hipótesis trata de evaluar la influencia de la cancelación gratuita, la cual para aportar una mayor diversidad en los análisis realizados, puede estar asociada a una posición distinta (inferior o superior) que la de un hotel sin cancelación gratuita. Definimos esta hipótesis mediante las hipótesis nula ($H_{0}$) y alternativa ($H_{1}$) siguientes:

* $H_{0}:$ La posición global de un hotel con cancelación gratuita y uno sin serán iguales.
* $H_{1}:$ La posición global de un hotel con cancelación gratuita será distinta a la de uno sin.

TEST NO PARAMETRICO AL NO PODER ASUMIR LA NORMALIDAD DE LOS DATOS

**Hipótesis 3**
A continuación evaluamos la influencia de la puntuación global del hotel. En este caso evaluaremos si un hotel con una puntuación global (**hotel_score**) superior o igual a un 9.0 obtiene un mejor posicionamiento que un hotel con una peor puntuación. A continuación se plantea la hipótesis nula ($H_{0}$) y la alternativa ($H_{1}$)

Los hoteles con una puntuación global superior a un 9 tendrán un mejor posicionamiento.

* $H_{0}:$ La posición global de un hotel con una puntuación global mayor o igual a 9.0 y uno con una puntuación inferior serán iguales.
* $H_{1}:$ La posición global de un hotel con una puntuación global mayor o igual a 9.0 será mejor (menor) que uno con una puntuación inferior.

TEST NO PARAMETRICO AL NO PODER ASUMIR LA NORMALIDAD DE LOS DATOS

**Hipótesis 4**
Finalmente evaluamos la influencia del precio mínimo del hotel considerando que un hotel con un menor precio mínimo tendrá un mejor posicionamiento. Para ello consideraremos las siguientes hipótesis nula ($H_{0}$) y alternativa ($H_{1}$)

Los hoteles con un precio mínimo inferior a la media tendrán un mejor posicionamiento.

* $H_{0}:$ La posición global de un hotel con precio mínimo inferior a la media y uno superior serán iguales.
* $H_{1}:$ La posición global de un hotel con precio mínimo inferior a la media será mejor (inferior) a la de uno con precio superior.

TEST NO PARAMETRICO AL NO PODER ASUMIR LA NORMALIDAD DE LOS DATOS

#### 4.4 Aplicación de funciones lineales para resolución del problema
Una vez analizados los distintos contrastes de hipótesis y hayada la correlación entre las distintas variables, tenemos un conocimiento del conjunto de datos lo suficientemente extenso como para analizar mediante una función lineal el posicionamiento de un hotel en el buscador de Booking.



## 5. REPRESENTACIÓN DE LOS RESULTADOS

A lo largo del documento se han presentado representaciones gráficas de los análisis realizados y de los resultados obtenidos.

## 6. RESOLUCIÓN DEL PROBLEMA
